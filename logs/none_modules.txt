['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.layers.24', 'model.layers.24.self_attn', 'model.layers.24.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.24.mlp', 'model.layers.24.mlp.gate_proj', 'model.layers.24.mlp.up_proj', 'model.layers.24.mlp.down_proj', 'model.layers.24.input_layernorm', 'model.layers.24.post_attention_layernorm', 'model.layers.25', 'model.layers.25.self_attn', 'model.layers.25.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.25.mlp', 'model.layers.25.mlp.gate_proj', 'model.layers.25.mlp.up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.25.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.26', 'model.layers.26.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.26.mlp', 'model.layers.26.mlp.gate_proj', 'model.layers.26.mlp.up_proj', 'model.layers.26.mlp.down_proj', 'model.layers.26.input_layernorm', 'model.layers.26.post_attention_layernorm', 'model.layers.27', 'model.layers.27.self_attn', 'model.layers.27.self_attn.q_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.27.mlp', 'model.layers.27.mlp.gate_proj', 'model.layers.27.mlp.up_proj', 'model.layers.27.mlp.down_proj', 'model.layers.27.input_layernorm', 'model.layers.27.post_attention_layernorm', 'model.norm', 'model.mm_projector', 'model.mm_projector.0', 'model.mm_projector.2', 'model.mm_inv_projector', 'model.mm_inv_projector.net', 'model.mm_inv_projector.net.x_embedder', 'model.mm_inv_projector.net.x_embedder.proj', 'model.mm_inv_projector.net.t_embedder', 'model.mm_inv_projector.net.t_embedder.mlp', 'model.mm_inv_projector.net.t_embedder.mlp.0', 'model.mm_inv_projector.net.t_embedder.mlp.2', 'model.mm_inv_projector.net.z_embedder', 'model.mm_inv_projector.net.z_embedder.1', 'model.mm_inv_projector.net.blocks', 'model.mm_inv_projector.net.blocks.0', 'model.mm_inv_projector.net.blocks.0.attn', 'model.mm_inv_projector.net.blocks.0.attn.qkv', 'model.mm_inv_projector.net.blocks.0.attn.proj', 'model.mm_inv_projector.net.blocks.0.mlp', 'model.mm_inv_projector.net.blocks.0.mlp.fc1', 'model.mm_inv_projector.net.blocks.0.mlp.fc2', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation', 'model.mm_inv_projector.net.blocks.0.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.1', 'model.mm_inv_projector.net.blocks.1.attn', 'model.mm_inv_projector.net.blocks.1.attn.qkv', 'model.mm_inv_projector.net.blocks.1.attn.proj', 'model.mm_inv_projector.net.blocks.1.mlp', 'model.mm_inv_projector.net.blocks.1.mlp.fc1', 'model.mm_inv_projector.net.blocks.1.mlp.fc2', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation', 'model.mm_inv_projector.net.blocks.1.adaLN_modulation.1', 'model.mm_inv_projector.net.blocks.2', 'model.mm_inv_projector.net.blocks.2.attn', 'model.mm_inv_projector.net.blocks.2.attn.qkv', 'model.mm_inv_projector.net.blocks.2.attn.proj', 'model.mm_inv_projector.net.blocks.2.mlp', 'model.mm_inv_projector.net.blocks.2.mlp.fc1', 'model.mm_inv_projector.net.blocks.2.mlp.fc2', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation', 'model.mm_inv_projector.net.blocks.2.adaLN_modulation.1', 'model.mm_inv_projector.net.final_layer', 'model.mm_inv_projector.net.final_layer.linear', 'model.mm_inv_projector.net.final_layer.adaLN_modulation', 'model.mm_inv_projector.net.final_layer.adaLN_modulation.1', 'lm_head']
